{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlatjdalsl/Phishing-Block/blob/main/stt_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 1. 설치 및 환경 준비\n",
        "!pip install SpeechRecognition pydub\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuWkj4BrepNF",
        "outputId": "248faf83-d365-4650-fc6d-d945e7ab109f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3 pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 2. Google Drive 마운트 및 파일 경로 설정\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "voice_file_path = '/content/drive/My Drive/Colab Notebooks/VoiceFile'\n",
        "text_save_path = '/content/drive/My Drive/Colab Notebooks/TextFile'\n",
        "os.makedirs(text_save_path, exist_ok=True)\n",
        "file_list = os.listdir(voice_file_path)\n",
        "print(\"📂 VoiceFile 목록:\")\n",
        "for file in file_list:\n",
        "    print(\"-\", file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU305kWre3aI",
        "outputId": "6dccbcc0-c2c0-4cbf-cc21-214a39696991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "VoiceFile 폴더 안의 파일 목록:\n",
            "test.wav\n",
            "model\n",
            "phishing\n",
            "normal\n",
            "음성을 불러오는 중...\n",
            "Google STT 변환 중...\n",
            "인식된 텍스트: 안녕하세요 하나 둘 셋 하나 둘 셋 저는 사기꾼입니다 보이스 피싱 저는 보이스피싱범입니다 돈을 빨리 보내 주셔야 지금 아들이 저랑 같이 있어요 지금 딸이 저랑 같이 있어요 지금 어머니가 크게 다치셨어요 지금 아버지가 크게 다치셨어요 안녕하세요 검찰 지금 대포 통장이 연료 되셨는데요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 3. Google STT + 텍스트 저장 함수\n",
        "import speech_recognition as sr\n",
        "\n",
        "def google_stt_from_drive(file_name):\n",
        "    recognizer = sr.Recognizer()\n",
        "    file_path = os.path.join(voice_file_path, file_name)\n",
        "    try:\n",
        "        with sr.AudioFile(file_path) as source:\n",
        "            print(\"🎧 음성 불러오기 중...\")\n",
        "            audio = recognizer.record(source)\n",
        "            print(\"🧠 Google STT 변환 중...\")\n",
        "            text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
        "            print(\"📝 텍스트:\", text)\n",
        "\n",
        "            # 텍스트 저장\n",
        "            base_name = os.path.splitext(file_name)[0] + \".txt\"\n",
        "            save_path = os.path.join(text_save_path, base_name)\n",
        "            with open(save_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(text)\n",
        "            print(f\"✅ 텍스트 저장 완료: {save_path}\")\n",
        "            return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"❌ 인식 실패\")\n",
        "    except sr.RequestError:\n",
        "        print(\"❌ Google API 오류\")\n",
        "    return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rs6dDUdFksi",
        "outputId": "1c5b6bac-4a00-4795-ef96-d43311ab6102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 데이터 개수: 15\n",
            "일반 대화: 7, 보이스피싱 대화: 8\n",
            "✅ 데이터 로드 및 전처리 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 4. 학습용 텍스트 데이터 로딩 및 전처리\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "normal_path = f'{voice_file_path}/normal'\n",
        "phishing_path = f'{voice_file_path}/phishing'\n",
        "\n",
        "def load_texts_from_folder(folder_path, label):\n",
        "    texts, labels = [], []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as f:\n",
        "                texts.append(f.read().strip())\n",
        "                labels.append(label)\n",
        "    return texts, labels\n",
        "\n",
        "normal_texts, normal_labels = load_texts_from_folder(normal_path, 0)\n",
        "phishing_texts, phishing_labels = load_texts_from_folder(phishing_path, 1)\n",
        "texts = normal_texts + phishing_texts\n",
        "labels = normal_labels + phishing_labels\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = pad_sequences(sequences, maxlen=200)\n",
        "labels = np.array(labels)\n",
        "print(f\"✅ 총 텍스트 수: {len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM5wqsSkF4Ky",
        "outputId": "a23d8a6c-c457-49b4-ac40-908711b8a934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8250 - loss: 0.6895\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9139 - loss: 0.6775\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6643\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.6461\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.6257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 학습 및 저장 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOqw_w5WINP4",
        "outputId": "e96ecc89-37b8-4210-8b89-2c83d08e4f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 5. LSTM 모델 학습 및 저장\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import pickle\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
        "    LSTM(64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded, labels, epochs=5, batch_size=8)\n",
        "\n",
        "model_path = f'{voice_file_path}/model'\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "model.save(f\"{model_path}/phishing_model.h5\")\n",
        "with open(f\"{model_path}/tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"✅ 모델 저장 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-UbWreBsQbo",
        "outputId": "a16d93fc-2a13-47aa-f5b3-137d4ea7be7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "🔁 모델과 토크나이저 로딩 중...\n",
            "✅ 모델 로딩 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANk6dMFwekH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 6. 음성 분석 + 위험도 예측 함수\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(f\"{model_path}/phishing_model.h5\")\n",
        "with open(f\"{model_path}/tokenizer.pkl\", 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "def analyze_audio_risk(file_name, threshold=0.5):\n",
        "    text = google_stt_from_drive(file_name)\n",
        "    if not text:\n",
        "        return None, None\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded_seq = pad_sequences(seq, maxlen=100)\n",
        "    prediction = model.predict(padded_seq)[0][0]\n",
        "    print(f\"📊 위험도: {prediction:.4f}\")\n",
        "    print(\"🚨 보이스피싱 가능성 높음!\" if prediction > threshold else \"✅ 정상 대화\")\n",
        "    return text, prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vkXJkpxvCM6",
        "outputId": "9fe953ed-d195-496b-a3dc-40f9bc28c2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 VoiceFile 폴더 안의 파일 목록:\n",
            "- test.wav\n",
            "- model\n",
            "- phishing\n",
            "- normal\n",
            "🎧 음성 파일 불러오는 중: test.wav\n",
            "🔁 Google STT 변환 중...\n",
            "📝 인식된 텍스트: 안녕하세요 하나 둘 셋 하나 둘 셋 저는 사기꾼입니다 보이스 피싱 저는 보이스피싱범입니다 돈을 빨리 보내 주셔야 지금 아들이 저랑 같이 있어요 지금 딸이 저랑 같이 있어요 지금 어머니가 크게 다치셨어요 지금 아버지가 크게 다치셨어요 안녕하세요 검찰 지금 대포 통장이 연료 되셨는데요\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "📊 위험도 예측값: 0.0970\n",
            "✅ 정상 대화로 판단됨\n",
            "\n",
            "📊 위험도: 0.0970\n",
            "✅ 위험도 낮아 LLM 분석 생략\n",
            "💬 최종 판단: 정상 대화로 간주\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 7. LLM 분석 함수 (OpenRouter API)\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"your-api-key\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "def llm_analysis(text, risk_score, threshold=0.5):\n",
        "    if risk_score <= threshold:\n",
        "        print(\"✅ 위험도 낮음 → LLM 생략\")\n",
        "        return \"정상 대화로 간주\"\n",
        "    print(\"🔎 LLM 분석 시작\")\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"tngtech/deepseek-r1t-chimera:free\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"당신은 보이스피싱 탐지 전문가입니다. ...\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ]\n",
        "        )\n",
        "        result = response.choices[0].message.content.strip()\n",
        "        print(\"📢 LLM 분석 결과:\", result)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(\"❌ LLM 오류:\", e)\n",
        "        return \"분석 실패\""
      ],
      "metadata": {
        "id": "s0rosG-t09lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 8. 전체 분석 실행 셀\n",
        "if file_list:\n",
        "    test_file = file_list[0]\n",
        "    text, risk_score = analyze_audio_risk(test_file)\n",
        "    if text:\n",
        "        final = llm_analysis(text, risk_score)\n",
        "        print(\"💬 최종 판단:\", final)\n",
        "else:\n",
        "    print(\"❗ 분석할 파일이 없습니다.\")"
      ],
      "metadata": {
        "id": "9yZDX2VN1Di3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}